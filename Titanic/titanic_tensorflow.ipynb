{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data reading\n",
    "with open('./data/titanicTrain.csv', 'r') as f:\n",
    "    data = list(csv.reader((f)))\n",
    "    data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pclass', 'sex', 'parch', 'fare'], \n",
       "      dtype='<U82')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:1000]\n",
    "data[0, [0, 3, 4, 5, 6, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['pclass', 'survived', 'name', ..., 'boat', 'body', 'home.dest'],\n",
       "       ['1', '1', 'Allen, Miss. Elisabeth Walton', ..., '2', '',\n",
       "        'St Louis, MO'],\n",
       "       ['1', '1', 'Allison, Master. Hudson Trevor', ..., '11', '',\n",
       "        'Montreal, PQ / Chesterville, ON'],\n",
       "       ..., \n",
       "       ['3', '0', 'Markun, Mr. Johann', ..., '', '', ''],\n",
       "       ['3', '1', 'Masselmani, Mrs. Fatima', ..., 'C', '', ''],\n",
       "       ['3', '0', 'Matinoff, Mr. Nicola', ..., '', '', '']], \n",
       "      dtype='<U82')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((999, 9), (999, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_clean(data, withLabel=True):\n",
    "    x_train = data[1:, [0, 3, 4, 5, 6, 8]]\n",
    "    y_label = data[1:, 1]\n",
    "    y_train = list()\n",
    "    pclass = list()\n",
    "    sex = list()\n",
    "    embarked = list()\n",
    "    for i in range(len(x_train)):\n",
    "        # sex -- class data one hot\n",
    "        if x_train[i, 1] == 'male':\n",
    "            sex.append([5, 0])\n",
    "        else:\n",
    "            sex.append([0, 5])\n",
    "        # age\n",
    "        if x_train[i, 2] == '':\n",
    "            x_train[i, 2] = '-100'\n",
    "        # fare\n",
    "        if x_train[i, 5] == '':\n",
    "            x_train[i, 5] = '-200'\n",
    "        # pclass -- class data one hot\n",
    "        if x_train[i, 0] == '1':\n",
    "            pclass.append([1, 0, 0])\n",
    "        elif x_train[i, 0] == '2':\n",
    "            pclass.append([0, 1, 0])\n",
    "        else:\n",
    "            pclass.append([0, 0, 1])\n",
    "        # labels one hot\n",
    "        if y_label[i] == '0':\n",
    "            y_train.append([1, 0])\n",
    "        else:\n",
    "            y_train.append([0, 1])\n",
    "    y_train = np.array(y_train)\n",
    "    sex = np.array(sex)\n",
    "    pclass = np.array(pclass)\n",
    "    x_train = x_train[:, [2, 3, 4, 5]].astype('float32')\n",
    "    # normalization\n",
    "    x_train[:, 0] = x_train[:, 0]/100\n",
    "    x_train[:, 1] = x_train[:, 1]/6\n",
    "    x_train[:, 2] = x_train[:, 2]/6\n",
    "    x_train[:, 3] = x_train[:, 2]/200\n",
    "    # combination of class-data and continuous data\n",
    "    x_train = np.hstack([pclass, sex, x_train])\n",
    "    if withLabel: \n",
    "        return x_train, y_train\n",
    "    else:\n",
    "        return x_train\n",
    "\n",
    "x_train, y_train = data_clean(data)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 800)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random splitting of training set and testing set\n",
    "ind = np.arange(len(x_train))\n",
    "np.random.shuffle(ind)\n",
    "ind_train = ind[0:int(len(x_train)*0.8)+1]\n",
    "ind_test = ind[int(len(x_train)*0.8)+1:]\n",
    "x_test = x_train[ind_test]\n",
    "y_test = y_train[ind_test]\n",
    "x_train = x_train[ind_train]\n",
    "y_train = y_train[ind_train]\n",
    "len(x_test), len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data\n",
    "with open('./data/titanicQuestion.csv', 'r') as f:\n",
    "    data_valid = list(csv.reader((f)))\n",
    "    data_valid = np.array(data_valid)\n",
    "\n",
    "x_valid = data_clean(data_valid, withLabel=False)\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'0': 577, '1': 422})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(data[1:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 2000\n",
    "l_r = 1e-4\n",
    "n_in = len(x_train[0])\n",
    "n_out = len(y_train[0])\n",
    "neuron_number = [n_in, 128, 128, n_out]\n",
    "keep_prob = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_in])\n",
    "y = tf.placeholder(tf.float32, [None, n_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _weight(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def _bias(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _add_layer(x, n1, n2):\n",
    "    # create weight and bias by the previous neuron number and next neuron number\n",
    "    w = _weight([n1, n2])\n",
    "    b = _bias([n2])\n",
    "    l = tf.add(tf.matmul(x, w), b, name='nn')\n",
    "    return l, w, b\n",
    "\n",
    "def DNN(neuron_number, x, hidden_act=tf.nn.relu, isLog=False, out_act=tf.nn.softmax, keep_prob=.9):\n",
    "    # neuron_number: array of neuron numbers for each layer, include input layer and output layer\n",
    "    weights = dict()\n",
    "    biases = dict()\n",
    "    layers = dict()\n",
    "    layers[0] = x\n",
    "    # create layers\n",
    "    for n in range(len(neuron_number)-1):\n",
    "        layers[n+1], weights[n+1], biases[n+1] = _add_layer(layers[n],\n",
    "                                                            neuron_number[n],\n",
    "                                                            neuron_number[n+1])\n",
    "        if n == (len(neuron_number)-2):\n",
    "            if out_act == None:\n",
    "                pass\n",
    "            else:\n",
    "                layers[n+1] = out_act(layers[n+1])\n",
    "        else:\n",
    "            if hidden_act == None:\n",
    "                pass\n",
    "            else:\n",
    "                layers[n+1] = hidden_act(layers[n+1])\n",
    "            layers[n+1] = tf.nn.dropout(layers[n+1], keep_prob=keep_prob)\n",
    "    return layers, weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <tf.Tensor 'Placeholder:0' shape=(?, 9) dtype=float32>,\n",
       " 1: <tf.Tensor 'dropout/mul:0' shape=(?, 128) dtype=float32>,\n",
       " 2: <tf.Tensor 'dropout_1/mul:0' shape=(?, 128) dtype=float32>,\n",
       " 3: <tf.Tensor 'Softmax:0' shape=(?, 2) dtype=float32>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers, weights, biases = DNN(neuron_number=neuron_number, \n",
    "                              x=x,\n",
    "                              hidden_act=tf.nn.relu,\n",
    "                              out_act=tf.nn.softmax,\n",
    "                              keep_prob=keep_prob)\n",
    "pred = layers[len(neuron_number)-1]\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss func, accu and op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "accu = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)), tf.float32))\n",
    "op = tf.train.RMSPropOptimizer(l_r).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 , TrainLoss: [ 0.617] , TrainAccu: [ 0.775] , TestLoss: [ 0.626] , TestAccu: [ 0.749]\n",
      "Epoch: 200 , TrainLoss: [ 0.534] , TrainAccu: [ 0.791] , TestLoss: [ 0.554] , TestAccu: [ 0.764]\n",
      "Epoch: 300 , TrainLoss: [ 0.523] , TrainAccu: [ 0.791] , TestLoss: [ 0.549] , TestAccu: [ 0.764]\n",
      "Epoch: 400 , TrainLoss: [ 0.513] , TrainAccu: [ 0.795] , TestLoss: [ 0.536] , TestAccu: [ 0.769]\n",
      "Epoch: 500 , TrainLoss: [ 0.51] , TrainAccu: [ 0.79] , TestLoss: [ 0.53] , TestAccu: [ 0.789]\n",
      "Epoch: 600 , TrainLoss: [ 0.508] , TrainAccu: [ 0.791] , TestLoss: [ 0.533] , TestAccu: [ 0.759]\n",
      "Epoch: 700 , TrainLoss: [ 0.506] , TrainAccu: [ 0.791] , TestLoss: [ 0.533] , TestAccu: [ 0.784]\n",
      "Epoch: 800 , TrainLoss: [ 0.5] , TrainAccu: [ 0.805] , TestLoss: [ 0.538] , TestAccu: [ 0.764]\n",
      "Epoch: 900 , TrainLoss: [ 0.5] , TrainAccu: [ 0.811] , TestLoss: [ 0.537] , TestAccu: [ 0.774]\n",
      "Epoch: 1000 , TrainLoss: [ 0.504] , TrainAccu: [ 0.798] , TestLoss: [ 0.532] , TestAccu: [ 0.769]\n",
      "Epoch: 1100 , TrainLoss: [ 0.498] , TrainAccu: [ 0.812] , TestLoss: [ 0.535] , TestAccu: [ 0.769]\n",
      "Epoch: 1200 , TrainLoss: [ 0.499] , TrainAccu: [ 0.806] , TestLoss: [ 0.537] , TestAccu: [ 0.754]\n",
      "Epoch: 1300 , TrainLoss: [ 0.502] , TrainAccu: [ 0.803] , TestLoss: [ 0.529] , TestAccu: [ 0.789]\n",
      "Epoch: 1400 , TrainLoss: [ 0.501] , TrainAccu: [ 0.803] , TestLoss: [ 0.54] , TestAccu: [ 0.749]\n",
      "Epoch: 1500 , TrainLoss: [ 0.5] , TrainAccu: [ 0.808] , TestLoss: [ 0.535] , TestAccu: [ 0.769]\n",
      "Epoch: 1600 , TrainLoss: [ 0.501] , TrainAccu: [ 0.8] , TestLoss: [ 0.537] , TestAccu: [ 0.769]\n",
      "Epoch: 1700 , TrainLoss: [ 0.499] , TrainAccu: [ 0.803] , TestLoss: [ 0.537] , TestAccu: [ 0.769]\n",
      "Epoch: 1800 , TrainLoss: [ 0.498] , TrainAccu: [ 0.806] , TestLoss: [ 0.536] , TestAccu: [ 0.769]\n",
      "Epoch: 1900 , TrainLoss: [ 0.497] , TrainAccu: [ 0.809] , TestLoss: [ 0.537] , TestAccu: [ 0.764]\n",
      "Epoch: 2000 , TrainLoss: [ 0.495] , TrainAccu: [ 0.807] , TestLoss: [ 0.538] , TestAccu: [ 0.759]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "init = tf.global_variables_initializer()\n",
    "np.set_printoptions(precision=3)\n",
    "batch_size = 800\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epo in range(epoch):\n",
    "        for i in range(int(len(x_train)/batch_size)):\n",
    "            sess.run(op, feed_dict={\n",
    "                x:x_train[i*batch_size:(i+1)*batch_size],\n",
    "                y:y_train[i*batch_size:(i+1)*batch_size]\n",
    "            })\n",
    "        if (epo+1)%100 == 0:\n",
    "            loss_train, accu_train = sess.run([loss, accu], feed_dict={\n",
    "                x:x_train,\n",
    "                y:y_train\n",
    "            })\n",
    "            loss_test, accu_test = sess.run([loss, accu], feed_dict={\n",
    "                x:x_test,\n",
    "                y:y_test\n",
    "            })\n",
    "            loss_train = np.array([loss_train])\n",
    "            accu_train = np.array([accu_train])\n",
    "            loss_test = np.array([loss_test])\n",
    "            accu_test = np.array([accu_test])\n",
    "            print('Epoch:', epo+1,\n",
    "                  ', TrainLoss:', loss_train,\n",
    "                  ', TrainAccu:', accu_train,\n",
    "                  ', TestLoss:', loss_test,\n",
    "                  ', TestAccu:', accu_test)\n",
    "    pred_q = sess.run(pred, feed_dict={\n",
    "        x:x_valid\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 260, 1: 49}),\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sur = [np.argmax(pred_q[i]) for i in range(len(pred_q))]\n",
    "Counter(sur), sur\n",
    "# 1:  258, 51\n",
    "# 2:  252, 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pred_result_tfver.csv', 'w') as f:\n",
    "    for i in range(len(sur)):\n",
    "        f.write(str(sur[i])+', \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.000e+00,   1.136e-10],\n",
       "       [  9.989e-01,   1.113e-03],\n",
       "       [  9.958e-01,   4.196e-03],\n",
       "       [  1.000e+00,   2.761e-12],\n",
       "       [  2.604e-03,   9.974e-01],\n",
       "       [  1.000e+00,   1.772e-10],\n",
       "       [  3.793e-03,   9.962e-01],\n",
       "       [  9.083e-02,   9.092e-01],\n",
       "       [  9.555e-01,   4.449e-02],\n",
       "       [  1.000e+00,   1.835e-09],\n",
       "       [  1.000e+00,   3.027e-08],\n",
       "       [  9.313e-01,   6.873e-02],\n",
       "       [  3.819e-02,   9.618e-01],\n",
       "       [  1.401e-03,   9.986e-01],\n",
       "       [  1.049e-02,   9.895e-01],\n",
       "       [  1.000e+00,   1.903e-12],\n",
       "       [  1.000e+00,   4.642e-11],\n",
       "       [  1.000e+00,   1.686e-07],\n",
       "       [  1.000e+00,   3.219e-11],\n",
       "       [  1.000e+00,   5.033e-08],\n",
       "       [  1.000e+00,   1.180e-07],\n",
       "       [  1.000e+00,   2.468e-07],\n",
       "       [  1.000e+00,   9.915e-12],\n",
       "       [  5.197e-03,   9.948e-01],\n",
       "       [  1.000e+00,   9.170e-09],\n",
       "       [  9.999e-01,   1.317e-04],\n",
       "       [  1.187e-01,   8.813e-01],\n",
       "       [  1.000e+00,   2.305e-10],\n",
       "       [  7.855e-01,   2.145e-01],\n",
       "       [  1.000e+00,   1.621e-10],\n",
       "       [  1.000e+00,   6.331e-10],\n",
       "       [  1.000e+00,   9.455e-10],\n",
       "       [  1.000e+00,   1.621e-10],\n",
       "       [  1.000e+00,   1.801e-12],\n",
       "       [  1.000e+00,   2.172e-09],\n",
       "       [  1.000e+00,   3.150e-09],\n",
       "       [  9.994e-01,   6.335e-04],\n",
       "       [  1.238e-03,   9.988e-01],\n",
       "       [  1.000e+00,   6.560e-11],\n",
       "       [  3.910e-03,   9.961e-01],\n",
       "       [  5.937e-01,   4.063e-01],\n",
       "       [  1.000e+00,   1.251e-11],\n",
       "       [  5.463e-01,   4.537e-01],\n",
       "       [  7.875e-01,   2.125e-01],\n",
       "       [  2.834e-02,   9.717e-01],\n",
       "       [  1.000e+00,   2.278e-07],\n",
       "       [  1.000e+00,   1.744e-07],\n",
       "       [  7.531e-02,   9.247e-01],\n",
       "       [  1.734e-03,   9.983e-01],\n",
       "       [  1.000e+00,   3.108e-06],\n",
       "       [  3.439e-02,   9.656e-01],\n",
       "       [  1.000e+00,   1.719e-08],\n",
       "       [  1.000e+00,   1.276e-10],\n",
       "       [  1.000e+00,   3.905e-11],\n",
       "       [  4.569e-03,   9.954e-01],\n",
       "       [  1.000e+00,   3.302e-11],\n",
       "       [  1.000e+00,   8.187e-08],\n",
       "       [  8.173e-01,   1.827e-01],\n",
       "       [  8.398e-01,   1.602e-01],\n",
       "       [  1.000e+00,   8.333e-09],\n",
       "       [  1.726e-01,   8.274e-01],\n",
       "       [  7.332e-01,   2.668e-01],\n",
       "       [  1.000e+00,   1.661e-07],\n",
       "       [  1.000e+00,   3.236e-10],\n",
       "       [  1.000e+00,   1.851e-09],\n",
       "       [  1.000e+00,   6.665e-08],\n",
       "       [  1.000e+00,   1.037e-08],\n",
       "       [  3.642e-01,   6.358e-01],\n",
       "       [  1.000e+00,   8.381e-13],\n",
       "       [  1.000e+00,   7.151e-10],\n",
       "       [  1.000e+00,   3.044e-11],\n",
       "       [  5.568e-01,   4.432e-01],\n",
       "       [  1.000e+00,   3.888e-11],\n",
       "       [  1.000e+00,   7.850e-12],\n",
       "       [  1.000e+00,   5.219e-11],\n",
       "       [  1.000e+00,   6.820e-08],\n",
       "       [  1.374e-02,   9.863e-01],\n",
       "       [  3.049e-03,   9.970e-01],\n",
       "       [  2.699e-04,   9.997e-01],\n",
       "       [  6.211e-01,   3.789e-01],\n",
       "       [  1.000e+00,   2.165e-11],\n",
       "       [  5.733e-03,   9.943e-01],\n",
       "       [  9.999e-01,   9.749e-05],\n",
       "       [  1.000e+00,   2.740e-08],\n",
       "       [  1.000e+00,   6.421e-08],\n",
       "       [  1.000e+00,   1.440e-11],\n",
       "       [  7.532e-01,   2.468e-01],\n",
       "       [  1.000e+00,   2.968e-08],\n",
       "       [  1.000e+00,   3.214e-09],\n",
       "       [  1.000e+00,   1.770e-07],\n",
       "       [  3.746e-01,   6.254e-01],\n",
       "       [  3.232e-01,   6.768e-01],\n",
       "       [  1.000e+00,   7.734e-08],\n",
       "       [  1.000e+00,   2.413e-07],\n",
       "       [  8.556e-01,   1.444e-01],\n",
       "       [  1.233e-02,   9.877e-01],\n",
       "       [  1.000e+00,   1.144e-08],\n",
       "       [  1.000e+00,   1.585e-07],\n",
       "       [  9.426e-01,   5.744e-02],\n",
       "       [  9.537e-01,   4.631e-02],\n",
       "       [  9.720e-01,   2.803e-02],\n",
       "       [  1.000e+00,   8.848e-11],\n",
       "       [  1.000e+00,   7.318e-10],\n",
       "       [  1.000e+00,   9.920e-11],\n",
       "       [  1.000e+00,   6.288e-11],\n",
       "       [  1.000e+00,   4.436e-11],\n",
       "       [  1.000e+00,   9.341e-06],\n",
       "       [  1.000e+00,   7.190e-08],\n",
       "       [  1.000e+00,   1.135e-07],\n",
       "       [  1.000e+00,   1.279e-09],\n",
       "       [  1.000e+00,   5.518e-09],\n",
       "       [  1.000e+00,   1.463e-05],\n",
       "       [  2.220e-02,   9.778e-01],\n",
       "       [  1.440e-02,   9.856e-01],\n",
       "       [  1.000e+00,   1.123e-10],\n",
       "       [  1.000e+00,   2.586e-11],\n",
       "       [  1.000e+00,   7.105e-12],\n",
       "       [  1.000e+00,   1.783e-07],\n",
       "       [  1.000e+00,   6.360e-08],\n",
       "       [  1.000e+00,   1.169e-07],\n",
       "       [  1.000e+00,   3.701e-08],\n",
       "       [  1.000e+00,   2.358e-09],\n",
       "       [  9.661e-01,   3.393e-02],\n",
       "       [  9.997e-01,   3.178e-04],\n",
       "       [  2.825e-03,   9.972e-01],\n",
       "       [  1.000e+00,   7.428e-08],\n",
       "       [  7.803e-01,   2.197e-01],\n",
       "       [  1.000e+00,   1.119e-07],\n",
       "       [  1.000e+00,   5.307e-12],\n",
       "       [  1.000e+00,   1.141e-08],\n",
       "       [  2.215e-01,   7.785e-01],\n",
       "       [  1.000e+00,   2.246e-08],\n",
       "       [  1.000e+00,   2.064e-11],\n",
       "       [  1.000e+00,   1.815e-07],\n",
       "       [  1.000e+00,   4.356e-08],\n",
       "       [  1.000e+00,   5.675e-12],\n",
       "       [  2.754e-03,   9.972e-01],\n",
       "       [  1.000e+00,   1.411e-11],\n",
       "       [  1.000e+00,   3.714e-12],\n",
       "       [  1.000e+00,   1.228e-08],\n",
       "       [  1.000e+00,   7.880e-08],\n",
       "       [  1.000e+00,   1.887e-10],\n",
       "       [  1.000e+00,   1.562e-10],\n",
       "       [  1.000e+00,   1.153e-10],\n",
       "       [  1.000e+00,   2.426e-10],\n",
       "       [  1.000e+00,   3.404e-10],\n",
       "       [  1.000e+00,   2.363e-05],\n",
       "       [  5.298e-01,   4.702e-01],\n",
       "       [  1.000e+00,   2.035e-09],\n",
       "       [  5.217e-03,   9.948e-01],\n",
       "       [  1.000e+00,   2.354e-11],\n",
       "       [  5.093e-03,   9.949e-01],\n",
       "       [  1.000e+00,   5.182e-11],\n",
       "       [  1.000e+00,   4.275e-05],\n",
       "       [  1.000e+00,   1.186e-09],\n",
       "       [  1.000e+00,   1.030e-11],\n",
       "       [  8.054e-03,   9.919e-01],\n",
       "       [  1.000e+00,   5.518e-06],\n",
       "       [  7.536e-01,   2.464e-01],\n",
       "       [  7.500e-02,   9.250e-01],\n",
       "       [  1.000e+00,   2.151e-11],\n",
       "       [  1.000e+00,   3.745e-07],\n",
       "       [  1.000e+00,   1.683e-11],\n",
       "       [  1.000e+00,   3.019e-11],\n",
       "       [  1.000e+00,   3.723e-12],\n",
       "       [  1.000e+00,   3.184e-08],\n",
       "       [  1.000e+00,   6.045e-09],\n",
       "       [  1.000e+00,   3.008e-09],\n",
       "       [  1.000e+00,   1.989e-10],\n",
       "       [  1.000e+00,   2.420e-09],\n",
       "       [  1.000e+00,   7.059e-24],\n",
       "       [  1.000e+00,   1.959e-21],\n",
       "       [  1.000e+00,   4.697e-18],\n",
       "       [  1.000e+00,   4.419e-19],\n",
       "       [  1.000e+00,   1.261e-17],\n",
       "       [  1.000e+00,   2.443e-18],\n",
       "       [  1.000e+00,   1.879e-21],\n",
       "       [  1.000e+00,   2.023e-20],\n",
       "       [  1.000e+00,   6.423e-21],\n",
       "       [  1.000e+00,   3.199e-22],\n",
       "       [  1.000e+00,   1.514e-19],\n",
       "       [  1.000e+00,   2.866e-08],\n",
       "       [  3.286e-01,   6.714e-01],\n",
       "       [  1.000e+00,   1.436e-09],\n",
       "       [  1.000e+00,   1.101e-10],\n",
       "       [  1.000e+00,   6.799e-12],\n",
       "       [  1.000e+00,   2.295e-12],\n",
       "       [  1.755e-02,   9.824e-01],\n",
       "       [  2.759e-02,   9.724e-01],\n",
       "       [  1.446e-02,   9.855e-01],\n",
       "       [  1.000e+00,   3.999e-08],\n",
       "       [  1.000e+00,   5.834e-08],\n",
       "       [  1.000e+00,   8.382e-08],\n",
       "       [  1.000e+00,   1.341e-07],\n",
       "       [  1.000e+00,   1.618e-11],\n",
       "       [  1.000e+00,   3.214e-10],\n",
       "       [  1.000e+00,   2.886e-08],\n",
       "       [  1.000e+00,   2.944e-10],\n",
       "       [  4.521e-03,   9.955e-01],\n",
       "       [  1.000e+00,   1.461e-10],\n",
       "       [  1.000e+00,   4.745e-11],\n",
       "       [  1.000e+00,   5.503e-08],\n",
       "       [  1.000e+00,   5.769e-11],\n",
       "       [  1.000e+00,   2.382e-09],\n",
       "       [  1.000e+00,   7.007e-08],\n",
       "       [  1.336e-01,   8.664e-01],\n",
       "       [  1.000e+00,   3.265e-09],\n",
       "       [  1.000e+00,   5.563e-09],\n",
       "       [  9.899e-01,   1.007e-02],\n",
       "       [  9.998e-01,   2.197e-04],\n",
       "       [  1.000e+00,   4.540e-10],\n",
       "       [  9.998e-01,   2.385e-04],\n",
       "       [  1.000e+00,   1.204e-11],\n",
       "       [  1.000e+00,   8.671e-12],\n",
       "       [  1.000e+00,   5.403e-11],\n",
       "       [  1.000e+00,   8.728e-12],\n",
       "       [  7.821e-03,   9.922e-01],\n",
       "       [  1.000e+00,   1.891e-07],\n",
       "       [  1.000e+00,   3.198e-08],\n",
       "       [  1.000e+00,   1.161e-10],\n",
       "       [  1.000e+00,   6.946e-09],\n",
       "       [  1.000e+00,   1.345e-11],\n",
       "       [  1.000e+00,   1.644e-08],\n",
       "       [  4.067e-01,   5.933e-01],\n",
       "       [  1.000e+00,   2.268e-07],\n",
       "       [  1.000e+00,   9.091e-12],\n",
       "       [  1.000e+00,   1.162e-07],\n",
       "       [  4.397e-01,   5.603e-01],\n",
       "       [  1.000e+00,   2.604e-08],\n",
       "       [  1.000e+00,   4.834e-08],\n",
       "       [  4.109e-03,   9.959e-01],\n",
       "       [  2.119e-01,   7.881e-01],\n",
       "       [  1.000e+00,   5.238e-07],\n",
       "       [  1.000e+00,   1.820e-10],\n",
       "       [  1.000e+00,   2.184e-07],\n",
       "       [  1.000e+00,   2.915e-14],\n",
       "       [  1.000e+00,   6.944e-07],\n",
       "       [  1.000e+00,   2.666e-08],\n",
       "       [  1.000e+00,   2.041e-07],\n",
       "       [  1.000e+00,   2.564e-09],\n",
       "       [  9.998e-01,   1.623e-04],\n",
       "       [  1.000e+00,   8.351e-12],\n",
       "       [  1.000e+00,   4.314e-11],\n",
       "       [  1.000e+00,   9.106e-11],\n",
       "       [  6.751e-02,   9.325e-01],\n",
       "       [  1.000e+00,   4.078e-10],\n",
       "       [  1.000e+00,   4.662e-10],\n",
       "       [  5.936e-01,   4.064e-01],\n",
       "       [  1.000e+00,   7.990e-09],\n",
       "       [  1.000e+00,   3.937e-10],\n",
       "       [  1.000e+00,   6.834e-10],\n",
       "       [  1.000e+00,   7.520e-09],\n",
       "       [  1.000e+00,   1.478e-10],\n",
       "       [  1.000e+00,   1.269e-10],\n",
       "       [  1.000e+00,   3.898e-08],\n",
       "       [  1.000e+00,   1.613e-11],\n",
       "       [  1.000e+00,   1.475e-05],\n",
       "       [  1.373e-02,   9.863e-01],\n",
       "       [  3.362e-02,   9.664e-01],\n",
       "       [  1.000e+00,   1.377e-08],\n",
       "       [  1.337e-01,   8.663e-01],\n",
       "       [  1.000e+00,   4.438e-06],\n",
       "       [  1.000e+00,   3.269e-09],\n",
       "       [  1.000e+00,   1.100e-05],\n",
       "       [  1.000e+00,   6.900e-07],\n",
       "       [  2.850e-03,   9.971e-01],\n",
       "       [  1.000e+00,   1.133e-07],\n",
       "       [  3.776e-01,   6.224e-01],\n",
       "       [  1.000e+00,   3.241e-11],\n",
       "       [  1.000e+00,   2.925e-08],\n",
       "       [  1.000e+00,   2.395e-08],\n",
       "       [  1.000e+00,   5.501e-08],\n",
       "       [  1.000e+00,   4.092e-10],\n",
       "       [  9.730e-01,   2.702e-02],\n",
       "       [  1.000e+00,   1.376e-11],\n",
       "       [  1.000e+00,   9.705e-09],\n",
       "       [  9.935e-01,   6.525e-03],\n",
       "       [  1.000e+00,   1.191e-07],\n",
       "       [  1.000e+00,   2.483e-07],\n",
       "       [  1.264e-01,   8.736e-01],\n",
       "       [  1.000e+00,   4.473e-08],\n",
       "       [  1.000e+00,   6.867e-08],\n",
       "       [  1.000e+00,   2.103e-09],\n",
       "       [  1.000e+00,   6.286e-10],\n",
       "       [  1.000e+00,   1.095e-11],\n",
       "       [  1.000e+00,   4.955e-09],\n",
       "       [  9.831e-01,   1.694e-02],\n",
       "       [  1.000e+00,   3.300e-11],\n",
       "       [  1.000e+00,   1.835e-07],\n",
       "       [  1.000e+00,   1.060e-07],\n",
       "       [  9.999e-01,   8.711e-05],\n",
       "       [  1.000e+00,   2.439e-10],\n",
       "       [  1.000e+00,   1.324e-11],\n",
       "       [  1.000e+00,   6.138e-12],\n",
       "       [  1.000e+00,   9.371e-09],\n",
       "       [  1.000e+00,   1.012e-07],\n",
       "       [  1.000e+00,   1.190e-07],\n",
       "       [  1.000e+00,   3.292e-10],\n",
       "       [  1.000e+00,   2.181e-09],\n",
       "       [  1.000e+00,   4.929e-08],\n",
       "       [  8.600e-01,   1.400e-01],\n",
       "       [  1.000e+00,   4.511e-11],\n",
       "       [  1.000e+00,   1.641e-11],\n",
       "       [  1.000e+00,   8.018e-12],\n",
       "       [  8.480e-01,   1.520e-01],\n",
       "       [  8.670e-01,   1.330e-01],\n",
       "       [  1.000e+00,   4.431e-08],\n",
       "       [  1.000e+00,   2.964e-08],\n",
       "       [  1.000e+00,   2.142e-08]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.one_hot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.]],\n",
       "\n",
       "       [[ 0.,  1.]],\n",
       "\n",
       "       [[ 1.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 1.,  0.]],\n",
       "\n",
       "       [[ 0.,  1.]],\n",
       "\n",
       "       [[ 1.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    one_hot = sess.run(tf.one_hot(y_train, depth=2))\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 1, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:, 0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
